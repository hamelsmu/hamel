{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfe69d6",
   "metadata": {},
   "source": [
    "# Writing Utils\n",
    "> Various utilities to help with writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9ae75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0380c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import httpx, os, subprocess\n",
    "from pathlib import Path\n",
    "from fastcore.utils import L\n",
    "from hamel import yt\n",
    "from hamel.gem import gem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g2o3j7g43l7",
   "metadata": {},
   "source": [
    "## PDF to Images\n",
    "\n",
    "Split PDF files into individual slide images. Requires poppler-utils installed (`brew install poppler` on macOS or `apt-get install poppler-utils` on Ubuntu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8443vlmqv4n",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def pdf2imgs(pdf_path, output_dir=\".\", prefix=\"slide\"):\n",
    "    \"Split a PDF file into individual slide images using poppler's pdftoppm.\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    cmd = [\"pdftoppm\", \"-png\", str(pdf_path), str(output_path / prefix)]\n",
    "    subprocess.run(cmd, check=True, capture_output=True)\n",
    "    created_files = sorted(output_path.glob(f\"{prefix}-*.png\"))\n",
    "    return [str(f.rename(output_path / f\"{prefix}_{i}.png\")) for i, f in enumerate(created_files, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x6ez4pr34n",
   "metadata": {},
   "source": [
    "For example, you can split the NewFrontiersInIR.pdf file into individual slide images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ve244jssq6g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 65 slide images in slides_output/\n"
     ]
    }
   ],
   "source": [
    "# Split NewFrontiersInIR.pdf into individual slides\n",
    "output_folder = \"slides_output\"\n",
    "image_files = pdf2imgs(\"NewFrontiersInIR.pdf\", output_dir=output_folder)\n",
    "\n",
    "# Show number of slides created\n",
    "print(f\"Created {len(image_files)} slide images in {output_folder}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de7ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf slides_output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab458b94",
   "metadata": {},
   "source": [
    "## Gather Context From Webpages\n",
    "\n",
    "I often want to gather context from a set of web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692929af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def jina_get(url):\n",
    "    \"Get a website as md with Jina.\"\n",
    "    if not (jkey := os.getenv('JINA_READER_KEY')): raise Exception('JINA_READER_KEY env variable not set.') \n",
    "    return httpx.get(f\"https://r.jina.ai/{url}\",\n",
    "                     headers = {\"Authorization\": f\"Bearer {jkey}\"},\n",
    "                     timeout=60).text\n",
    "\n",
    "def gather_urls(urls, tag='example'):\n",
    "    \"Gather contents from URLs.\"\n",
    "    xml=[f'<{tag}-{i+1}>\\n{c}\\n</{tag}-{i}>' for i,c in enumerate(urls.map(jina_get))]\n",
    "    return f'<{tag}s>\\n' + '\\n'.join(xml) + f'\\n<{tag}s>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a4970",
   "metadata": {},
   "source": [
    "For example, these are what I might use as context for annotated posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5d53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_annotated_post_urls = L(['https://raw.githubusercontent.com/hamelsmu/hamel-site/refs/heads/master/notes/llm/rag/p1-intro.md', 'https://raw.githubusercontent.com/hamelsmu/hamel-site/refs/heads/master/notes/llm/rag/p2-evals.md',\n",
    "'https://raw.githubusercontent.com/hamelsmu/hamel-site/refs/heads/master/notes/llm/evals/inspect.qmd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dac7260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<examples>\n",
      "<example-1>\n",
      "Title: \n",
      "\n",
      "URL Source: https://raw.githubusercontent.com/hamelsmu/hamel-site/refs/heads/master/notes/llm/rag/p1-intro.md\n",
      "\n",
      "Markdown Content:\n",
      "---\n",
      "title: \"P1: I don't use RAG, I just retrieve documents\"\n",
      "description: \"Ben Clavié's introduction to advanced retrieval techniques\"\n",
      "image: p1-images/slide_12.png\n",
      "date: 2025-06-25\n",
      "---\n",
      "\n",
      "As part of our [LLM Evals course](https://bit.ly/evals-ai){target=\"_blank\"}, I hosted [Benjamin Clavié](https://ben.clavie.eu/){target=\"_blank\"} to kick \n"
     ]
    }
   ],
   "source": [
    "_annotated_post_content = gather_urls(_annotated_post_urls)\n",
    "print(_annotated_post_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd065303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def outline_slides(slide_path):\n",
    "    return gem(\"Provide a numbered list of each slide with a one sentence summary of each.  Just a numbered list please, no other asides or meta explanations of the task are required.\", slide_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3c834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a one-sentence summary for each slide:\n",
      "\n",
      "1.  This slide introduces the presentation \"New Frontiers in IR: Instruction Following and Reasoning\" by Orion Weller from Johns Hopkins Whiting School of Engineering.\n",
      "2.  This slide shows a \"Message ChatGPT\" interface with a prominent \"Search\" button,\n"
     ]
    }
   ],
   "source": [
    "_o = outline_slides('NewFrontiersInIR.pdf')\n",
    "print(_o[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f68df",
   "metadata": {},
   "source": [
    "## Annotated Posts From Talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538f4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_annotated_talk_post(slide_path, \n",
    "                                 youtube_link, \n",
    "                                 image_dir,\n",
    "                                 transcript_path=None, \n",
    "                                 example_urls=_annotated_post_urls):\n",
    "    \"Assemble the prompt for the annotated post.\"\n",
    "    \n",
    "    youtube_chapters = yt.yt_chapters(youtube_link)\n",
    "    slide_outline = outline_slides(slide_path)\n",
    "    transcript =  Path(transcript_path).read_text() if transcript_path else yt.transcribe(youtube_link)\n",
    "    examples = gather_urls(example_urls)\n",
    "    _ = pdf2imgs(slide_path, output_dir=image_dir)\n",
    "    \n",
    "    prompt=f\"\"\"Attached is the transcript (in <transcript> tags) of a technical talk for the attached slides. I'd like to make an annotated presentation blog post as illustratd in <example-posts> tags.\n",
    "\n",
    "For each slide, provide a detailed synopsis of the information to maximize understanding for the reader for the purposes of educating the reader.  Each section should provide enough commentary and info to understand the full context of that particular slide.  The idea is that the reader will not have to watch the video and can instead read the material so the writing + slide should stand alone.  Do not simply repeat the information on each slide, briefly describe what the slide is about, and capture supplementary information that was provided in the talk that is NOT in the slides.   Be thoroughly detailed and capture useful asides or commentary as well, such that the notes you generate should be a legitimate value add on top of the slides.\n",
    "\n",
    "When writing the article, provide markdown placeholders with appropriate captions where the slides will go.  For example, you might have placeholder like this.\n",
    "\n",
    "[Overview of xyz concpet]({image_dir}/slide_1.png) \n",
    "\n",
    "Note that images for this post will be placed in {image_dir}/\n",
    "\n",
    "Refer to slides with naming convention (slide_1.png, slide_2.png, etc)\n",
    "\n",
    "Additionally, reference the correct timestamp in the form of a timestamped linked to the youtube video that corresponds to the start of each slide.   The link to this presentation is {youtube_link} (so use this when adding timestamps please).  \n",
    "\n",
    "I have included other annotated posts as an example for you to understand the format. These examples are in <examples> tags.\n",
    "\n",
    "Finally, there might be Q&A section of the talk that will not correspond to any slides at all.  If that exists, list all those questions with answers in a Q&A section.  If there is a Q&A section, it should be drafted to maximize learning such that people who have listened to the talk can understand the full context.  Add timestamps if possible to each question in the Q&A as well.  The post should be written from the perspective of Hamel Husain (me) who hosted the talk as part of a course on LLM Evals (https://bit.ly/evals-ai).   Put a CTA at the beginning and end of the post in a tasteful way that is appropriate for a developer blog that looks something like the example posts, particularly following `p1-intro.md`.  \n",
    "\n",
    "Example CTA: We are teaching our last and final cohort of our [AI Evals course](https://bit.ly/evals-ai) next month (we have to get back to building). Here is a [35% discount code](https://bit.ly/evals-ai) for readers.\n",
    "\n",
    "Here is the transcript\n",
    "<transcript>\n",
    "{transcript}\n",
    "</transcript>\n",
    "\n",
    "Incase it is helpful, here is here is the YouTube description with chapters from the talk.  However, please use timestamps from the transcript when possible when constructing timestamped links. \n",
    "<youtube-chapters>\n",
    "{youtube_chapters}\n",
    "</youtube-chapters>\n",
    "\n",
    "Below is a brief slide outline (in addition to the attached pdf)\n",
    "<slide-outline>\n",
    "{slide_outline}\n",
    "</slide-outline>\n",
    "\n",
    "Here are example posts that I have previously written:\n",
    "{examples}\n",
    "\n",
    "When writing the introduction, annotation and Q&A keep the following writing guidelines in mind:\n",
    "\n",
    "1. Do not add filler words. \n",
    "2. Make every sentence information-dense without repetition.\n",
    "3. Get to the point while providing necessary context.\n",
    "4. Use short words and fewer words.\n",
    "5. Avoid multiple examples if one suffices.\n",
    "6. Make questions neutral without telegraphing answers.\n",
    "7. Remove sentences that restate the premise.\n",
    "8. Cut transitional fluff like \"This is important because...\"\n",
    "9. Combine related ideas into single statements.\n",
    "10. Avoid overusing bullet points. Prefer flowing prose that combines related concepts. Use lists only for truly distinct items.\n",
    "11. Trust the reader's intelligence.\n",
    "12. Start sections with specific advice, not general statements.\n",
    "13. Replace em dashes with periods, commas, or colons.\n",
    "14. Cut qualifying phrases that add no concrete information.\n",
    "15. Use direct statements. Avoid hedge words unless exceptions matter.\n",
    "16. Remove setup phrases like \"It's worth noting that\" or \"The key point is.\"\n",
    "17. Avoid unnecessarily specific claims when general statements work.\n",
    "18. Avoid explanatory asides and redundant clauses.\n",
    "19. Each sentence should add new information.\n",
    "20. Avoid \"Remember... the goal is not X but Y\" conclusions.\n",
    "21. No emojis in professional writing.\n",
    "22. Use simple language. Present information objectively. Avoid exaggeration.\n",
    "23. No formulaic conclusions with labels and prescriptive wisdom.\n",
    "\n",
    "Please go ahead and draft the post. Please also include front matter similar to the front matter in the examples and select the best slide from the talk as the cover image (which is not the title slide, but instead another interesting slide that is punchy).\n",
    "\"\"\"\n",
    "    draft_post = gem(prompt, [slide_path, youtube_link], model='gemini-2.5-pro')\n",
    "    return draft_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8ff08",
   "metadata": {},
   "source": [
    "## Example Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9133c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = generate_annotated_talk_post(slide_path='orion_example/NewFrontiersInIR.pdf',\n",
    "                                    youtube_link='https://youtu.be/YB3b-wPbSH8?si=u_x0Puwreld3YCGf',\n",
    "                                    image_dir='orion_example/p3_images',\n",
    "                                    transcript_path='orion_example/transcript.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "731ea3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30263"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('orion_example/p3_orion.qmd').write_text(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e540a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
