{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd43e31c",
   "metadata": {},
   "source": [
    "# yt\n",
    "> Utilities for Content Creation From YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbf4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a2dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import re\n",
    "from typing import Optional, Annotated\n",
    "import typer\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from hamel.gem import gem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca83aa",
   "metadata": {},
   "source": [
    "## YouTube Chapter Creation\n",
    "\n",
    "Automate pesky chapter creation + description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cff3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def yt_chapters(link):\n",
    "    \"Generate YoutTube Summary and Chapters From A Public Video.\"\n",
    "    \n",
    "    chapter_prompt=\"Generate a succinct video summary (1-2 sentences) followed by YouTube chapter timestamps for this video. Format each line of the chapter summaries as 'MM:SS - Chapter Title' (e.g., '02:30 - Introduction'). Start with 00:00. Include all major topics and transitions and be thorough - do not miss any important topics.  For the summary, do not say 'In this video, we will cover the following topics', 'This video discusses..' or anything like that. Instead, reference the main speaker's name if you know it.  If there is a Q&A Section, enumerate individual questions as additional chapters.\"\n",
    "    return gem(prompt=chapter_prompt, o=link, model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191638",
   "metadata": {},
   "source": [
    "This is what it looks like for Antoine's [Late Interaction Talk](https://youtu.be/1x3k0V2IITo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1910f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this presentation, Antoine Chaffin explains the inherent limitations of single-vector search, such as information loss from pooling and poor out-of-domain performance, and introduces late interaction (multi-vector) models as a superior solution. He demonstrates how these models excel in long-context and reasoning-intensive tasks and presents the PyLate library to make training and evaluating these powerful models more accessible.\n",
      "\n",
      "00:00 - Introduction\n",
      "00:32 - About Me\n",
      "01:40 - Dense (Single) Vector Search Explained\n",
      "03:08 - Single Vector Models: The Go-To for RAG\n",
      "03:55 - Performance Evaluation & MTEB Leaderboard\n",
      "04:17 - The BEIR Benchmark & Goodhart's Law\n",
      "05:36 - Limitations Beyond Benchmarks: The Long Context Problem\n",
      "06:33 - Limitations Beyond Benchmarks: Reasoning-Intensive Retrieval\n",
      "07:50 - The Role of BM25\n",
      "08:24 - Pooling: The Intrinsic Flaw of Dense Models\n",
      "11:32 - Replacing Pooling with Late Interaction\n",
      "12:17 - Why Not Just Use a Bigger Single Vector?\n",
      "13:51 - Late Interaction: A Simple, Yet Effective, Difference\n",
      "16:48 - Interpretability: A Nice Little Bonus\n",
      "17:42 - Why Are People Still Using Dense Models?\n",
      "18:43 - PyLate: Extending Sentence Transformers for Multi-Vector Models\n",
      "21:28 - Training is Cool, Show Me the Evals\n",
      "22:49 - What Are the Future Avenues?\n",
      "24:36 - Conclusion & QR Codes\n",
      "25:52 - Q&A: Latency of Late Interaction vs. Dense Vector Models\n",
      "31:00 - Q&A: Does Fine-Tuning Close the Performance Gap?\n",
      "33:20 - Q&A: How Easy is it to Fine-Tune with PyLate?\n",
      "34:22 - Q&A: Common Mistakes When Moving from Single to Multi-Vector?\n"
     ]
    }
   ],
   "source": [
    "chp = yt_chapters(\"https://youtu.be/1x3k0V2IITo\")\n",
    "print(chp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fab76",
   "metadata": {},
   "source": [
    "## Fetch YouTube Transcript\n",
    "\n",
    "Fetch the youtube transcript from public videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ce4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _extract_video_id(url: str) -> Optional[str]:\n",
    "    \"\"\"Extract YouTube video ID from various URL formats.\"\"\"\n",
    "    for pattern in [r'(?:youtube\\.com/watch\\?v=|youtu\\.be/)([^&\\n?#]+)', \n",
    "                    r'youtube\\.com/embed/([^&\\n?#]+)', \n",
    "                    r'youtube\\.com/v/([^&\\n?#]+)']:\n",
    "        if match := re.search(pattern, url): return match.group(1)\n",
    "    return url if re.match(r'^[a-zA-Z0-9_-]{11}$', url) else None\n",
    "\n",
    "def _format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to HH:MM:SS format.\"\"\"\n",
    "    h, m, s = int(seconds // 3600), int((seconds % 3600) // 60), int(seconds % 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "        \n",
    "def _format_seconds(seconds: float): return f\"{int(seconds):d}s\"       \n",
    "\n",
    "        \n",
    "def transcribe(url, seconds_only = False):\n",
    "    \"Download YouTube transcript.\"\n",
    "    if not (video_id := _extract_video_id(url)): raise ValueError(f\"Could not extract video ID from '{url}'\")\n",
    "    try: transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "    except (TranscriptsDisabled, NoTranscriptFound) as e: raise ValueError(f\"{str(e)} for video: {video_id}\")\n",
    "    format_func = _format_seconds if seconds_only else _format_timestamp\n",
    "    transcript_text = '\\n'.join(f\"[{format_func(e['start'])}] {e['text']}\" for e in transcript_data)\n",
    "    return transcript_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4052f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transcribe(\"https://youtu.be/1x3k0V2IITo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3785b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00] Hello everyone, my name is Chapan and I\n",
      "[00:00:02] am a research engineer at Leighton and\n",
      "[00:00:05] today I will detail some of the limits\n",
      "[00:00:08] of single vector search that have been\n",
      "[00:00:10] highlighted by recent usages and\n",
      "[00:00:13] evaluations and then I will introduce\n",
      "[00:00:16] multi vector models also known as late\n",
      "[00:00:18] interaction models and how they can\n",
      "[00:00:21] overcome this and to finish I will\n",
      "[00:00:24] briefly present the pilot library that\n",
      "[00:00:26] al\n"
     ]
    }
   ],
   "source": [
    "print(t[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3d490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
