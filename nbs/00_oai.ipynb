{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oai\n",
    "\n",
    "> OpenAI utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp oai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from datetime import datetime\n",
    "import inspect, os, json, subprocess\n",
    "import pandas as pd\n",
    "from fastcore.script import call_parse\n",
    "from fastcore.meta import delegates\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _to_dt(dt:int):\n",
    "    return datetime.fromtimestamp(dt).strftime('%Y-%m-%d')\n",
    "\n",
    "@call_parse\n",
    "def list_models(owned:str=None, # Filter by who models are owned by\n",
    "                limit:int=None # Limit results to the most n created models.\n",
    "               ):\n",
    "    \"List OpenAI models you have access to.\"\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    models = list(client.models.list())\n",
    "    models.sort(key=lambda m: -m.created)\n",
    "    models = [{'Name': m.id, 'Created Dt': _to_dt(m.created)} for m in models if not owned or owned in m.owned_by]\n",
    "    if limit: models = models[:limit]\n",
    "    df = pd.DataFrame(models)\n",
    "    return df.to_markdown(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name                    | Created Dt   |\n",
      "|:------------------------|:-------------|\n",
      "| gpt-4                   | 2023-06-27   |\n",
      "| gpt-4-0314              | 2023-06-27   |\n",
      "| gpt-4-0613              | 2023-06-12   |\n",
      "| gpt-3.5-turbo-0613      | 2023-06-12   |\n",
      "| gpt-3.5-turbo-16k-0613  | 2023-05-30   |\n",
      "| gpt-3.5-turbo-16k       | 2023-05-10   |\n",
      "| tts-1                   | 2023-04-19   |\n",
      "| gpt-3.5-turbo-0301      | 2023-02-28   |\n",
      "| gpt-3.5-turbo           | 2023-02-28   |\n",
      "| whisper-1               | 2023-02-27   |\n",
      "| text-embedding-ada-002  | 2022-12-16   |\n",
      "| text-davinci-003        | 2022-11-27   |\n",
      "| curie-similarity        | 2022-04-28   |\n",
      "| babbage-search-document | 2022-04-28   |\n",
      "| ada-code-search-text    | 2022-04-28   |\n"
     ]
    }
   ],
   "source": [
    "print(list_models(owned='openai', limit=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _query_git_config(key: str):\n",
    "    try:\n",
    "        result = subprocess.check_output(['git', 'config', '--get', key])\n",
    "        str_res = result.decode().strip()\n",
    "        if key == 'remote.origin.url': return str_res.split('/')[-1][:-4]\n",
    "        return str_res\n",
    "    except subprocess.CalledProcessError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "assert _query_git_config('remote.origin.url') == 'hamel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def _join_url(base, path):\n",
    "    if not base.endswith('/'):\n",
    "        base += '/'\n",
    "    return urljoin(base, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def create_openai_plugin_scaffolding(name:str=None, # the name of your app for the LLM, ex: `todo`.  By default, this is inferred from the name of your git repo.\n",
    "                                     description:str=None, # the description of your application that will be read by the LLM.\n",
    "                                     url='http://localhost:8000', # The url of your function endpoint. \n",
    "                                     email=None, # The email associated with your app.  By default this is inferred by git.\n",
    "                                    ):\n",
    "    \"Generate minimal scaffolding for an OpenAI Plugin.\"\n",
    "    # Prompt for the application description\n",
    "    if not description: description = input(\"Enter the application description: \")\n",
    "    if not url: \n",
    "        _url = input(\"Change the url for the app (default: http://localhost:8000): \")\n",
    "        if url: url=_url\n",
    "\n",
    "    # Try to infer name_for_model and contact_email from Git config\n",
    "    if name: \n",
    "        name_for_model=name\n",
    "    else:\n",
    "        name_for_model = _query_git_config('remote.origin.url')\n",
    "        if name_for_model: print(f\"Inferred name of app for model and human as `{name_for_model.split('/')[-1]}`.  Modify .well-known/ai-plugin.json and main.py to change this.\")\n",
    "        else: name_for_model = input(\"Provide the name of your function for the model. (ex `todo`):\")\n",
    "        \n",
    "    if not email:\n",
    "        email = _query_git_config('user.email')\n",
    "        if not email: email = input(\"Enter the contact email: \")\n",
    "    \n",
    "    # Write the ai-plugin.json file\n",
    "    ai_plugin_info = {\n",
    "        \"schema_version\": \"v1\",\n",
    "        \"name_for_human\": name_for_model,  # Assuming the Git repo name is suitable for human-readable name\n",
    "        \"name_for_model\": name_for_model,\n",
    "        \"description_for_human\": description,\n",
    "        \"description_for_model\": description,\n",
    "        \"auth\": {\n",
    "            \"type\": \"none\"\n",
    "        },\n",
    "        \"api\": {\n",
    "            \"type\": \"openapi\",\n",
    "            \"url\": f\"{_join_url(url, 'openapi.yaml')}\"\n",
    "        },\n",
    "        \"logo_url\": f\"{_join_url(url, 'logo.png')}\",\n",
    "        \"contact_email\": email,\n",
    "        \"legal_info_url\": \"http://example.com/legal\"\n",
    "    }\n",
    "\n",
    "    os.makedirs('.well-known', exist_ok=True)\n",
    "    with open('.well-known/ai-plugin.json', 'w') as f:\n",
    "        json.dump(ai_plugin_info, f, indent=4)\n",
    "\n",
    "    # Write the main.py file\n",
    "    with open('main.py', 'w') as f:\n",
    "        f.write(\n",
    "            'from fastapi import FastAPI, Response, Request\\n'\n",
    "            'from fastapi.responses import FileResponse\\n'\n",
    "            'import yaml\\n\\n'\n",
    "            f'app = FastAPI(description=\"{description}\", title=\"{name_for_model}\")\\n\\n'  # Set description for FastAPI\n",
    "            '@app.get(\"/some-route\")\\n'\n",
    "            'async def example_route():\\n'\n",
    "            '    return {\"message\": \"Hello World\"}\\n\\n'\n",
    "            '@app.get(\"/.well-known/ai-plugin.json\", response_class=FileResponse)\\n'\n",
    "            'async def ai_plugin():\\n'\n",
    "            '    return FileResponse(\"my_plugin/.well-known/ai-plugin.json\")\\n\\n'\n",
    "            '@app.get(\"/logo.png\", response_class=FileResponse)\\n'\n",
    "            'async def plugin_logo():\\n'\n",
    "            '    return FileResponse(\"my_plugin/static/logo.png\")\\n\\n'\n",
    "            '@app.get(\"/openapi.yaml\")\\n'\n",
    "            'async def openapi(request: Request):\\n'\n",
    "            '    openapi_schema = app.openapi()\\n'\n",
    "            '    openapi_schema[\"servers\"] = [{\"url\": f\"https://{request.headers[\\'Host\\']}\"}]\\n'\n",
    "            '    for p in [\"/.well-known/ai-plugin.json\", \"/logo.png\", \"/openapi.yaml\"]:\\n'\n",
    "            '        openapi_schema[\"paths\"].pop(p)\\n'\n",
    "            '    return Response(content=yaml.dump(openapi_schema), media_type=\"text/yaml\")\\n\\n'\n",
    "        )\n",
    "\n",
    "    print('Plugin scaffolding created in current directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
